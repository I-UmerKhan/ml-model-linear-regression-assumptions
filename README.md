# ml-model-linear-regression-assumptions
I learned about the key assumptions of linear regression, which are essential for ensuring the model's validity and reliability. These assumptions include linearity, meaning the relationship between the independent and dependent variables should be linear, ensuring that changes in the dependent variable are proportional to changes in the independent variables. Independence assumes that the residuals (errors) are not correlated with each other, preventing any pattern or relationship between residuals of different observations. Homoscedasticity requires that residuals have constant variance at every level of the independent variables, maintaining a consistent spread of residuals across all values. The normality of errors assumption ensures that residuals are approximately normally distributed, which is crucial for hypothesis testing and constructing confidence intervals. Lastly, the absence of multicollinearity means that the independent variables should not be highly correlated with each other, as multicollinearity can inflate the variance of coefficient estimates, making the model unstable and difficult to interpret. Understanding and verifying these assumptions help in building accurate and unbiased linear regression models, leading to more reliable predictions and insights.
